{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"observations_train.csv\")\n",
    "test_df = pd.read_csv(\"obs_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date']=pd.to_datetime(train_df[\"date\"])\n",
    "test_df['date']=pd.to_datetime(test_df[\"date\"])\n",
    "test_df = test_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_df['series_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-08</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.163333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-09</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.156667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-11</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-13</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-14</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-15</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-16</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-17</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-18</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-19</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-20</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-21</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-22</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-23</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.096667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-24</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-25</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-26</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-27</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-28</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-29</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.053333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.076667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-01</th>\n",
       "      <td>AAA10Y</td>\n",
       "      <td>1.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>10.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-03</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>8.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>20.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-05</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>68.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>5.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>16.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>6.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-09</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-10</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>9.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>10.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>7.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>17.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>22.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-15</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>82.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-16</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>87.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-17</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>76.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-18</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>41.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-19</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>8.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-20</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>5.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-21</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>39.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-22</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>7.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-23</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>12.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-24</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>54.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-25</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>20.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>41.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>13.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>12.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>23.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>47.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>WLEMUINDXD</td>\n",
       "      <td>89.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367212 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             series_id      value\n",
       "2000-01-03      AAA10Y   1.170000\n",
       "2000-01-04      AAA10Y   1.200000\n",
       "2000-01-05      AAA10Y   1.160000\n",
       "2000-01-06      AAA10Y   1.150000\n",
       "2000-01-07      AAA10Y   1.170000\n",
       "2000-01-08      AAA10Y   1.163333\n",
       "2000-01-09      AAA10Y   1.156667\n",
       "2000-01-10      AAA10Y   1.150000\n",
       "2000-01-11      AAA10Y   1.140000\n",
       "2000-01-12      AAA10Y   1.130000\n",
       "2000-01-13      AAA10Y   1.170000\n",
       "2000-01-14      AAA10Y   1.150000\n",
       "2000-01-15      AAA10Y   1.150000\n",
       "2000-01-16      AAA10Y   1.150000\n",
       "2000-01-17      AAA10Y   1.150000\n",
       "2000-01-18      AAA10Y   1.150000\n",
       "2000-01-19      AAA10Y   1.140000\n",
       "2000-01-20      AAA10Y   1.100000\n",
       "2000-01-21      AAA10Y   1.070000\n",
       "2000-01-22      AAA10Y   1.083333\n",
       "2000-01-23      AAA10Y   1.096667\n",
       "2000-01-24      AAA10Y   1.110000\n",
       "2000-01-25      AAA10Y   1.070000\n",
       "2000-01-26      AAA10Y   1.040000\n",
       "2000-01-27      AAA10Y   0.990000\n",
       "2000-01-28      AAA10Y   1.030000\n",
       "2000-01-29      AAA10Y   1.053333\n",
       "2000-01-30      AAA10Y   1.076667\n",
       "2000-01-31      AAA10Y   1.100000\n",
       "2000-02-01      AAA10Y   1.070000\n",
       "...                ...        ...\n",
       "2017-12-02  WLEMUINDXD  10.260000\n",
       "2017-12-03  WLEMUINDXD   8.510000\n",
       "2017-12-04  WLEMUINDXD  20.410000\n",
       "2017-12-05  WLEMUINDXD  68.330000\n",
       "2017-12-06  WLEMUINDXD   5.840000\n",
       "2017-12-07  WLEMUINDXD  16.870000\n",
       "2017-12-08  WLEMUINDXD   6.670000\n",
       "2017-12-09  WLEMUINDXD  11.000000\n",
       "2017-12-10  WLEMUINDXD   9.570000\n",
       "2017-12-11  WLEMUINDXD  10.690000\n",
       "2017-12-12  WLEMUINDXD   7.930000\n",
       "2017-12-13  WLEMUINDXD  17.070000\n",
       "2017-12-14  WLEMUINDXD  22.810000\n",
       "2017-12-15  WLEMUINDXD  82.570000\n",
       "2017-12-16  WLEMUINDXD  87.350000\n",
       "2017-12-17  WLEMUINDXD  76.140000\n",
       "2017-12-18  WLEMUINDXD  41.470000\n",
       "2017-12-19  WLEMUINDXD   8.010000\n",
       "2017-12-20  WLEMUINDXD   5.560000\n",
       "2017-12-21  WLEMUINDXD  39.720000\n",
       "2017-12-22  WLEMUINDXD   7.340000\n",
       "2017-12-23  WLEMUINDXD  12.130000\n",
       "2017-12-24  WLEMUINDXD  54.870000\n",
       "2017-12-25  WLEMUINDXD  20.560000\n",
       "2017-12-26  WLEMUINDXD  41.350000\n",
       "2017-12-27  WLEMUINDXD  13.950000\n",
       "2017-12-28  WLEMUINDXD  12.770000\n",
       "2017-12-29  WLEMUINDXD  23.070000\n",
       "2017-12-30  WLEMUINDXD  47.600000\n",
       "2017-12-31  WLEMUINDXD  89.840000\n",
       "\n",
       "[367212 rows x 2 columns]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for col in np.unique(train_df['series_id']):\n",
    "    temp = train_df[train_df['series_id']==col].set_index('date')\n",
    "    idx = pd.date_range(min(np.unique(temp.index)), max(np.unique(temp.index)))\n",
    "    temp.index = pd.DatetimeIndex(temp.index)\n",
    "    temp = temp.reindex(idx, fill_value=None)\n",
    "    temp['series_id']=col\n",
    "    temp['value'] = temp['value'].interpolate(method='time')\n",
    "    df_train = df_train.append(temp)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data within the SP500 timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for col in np.unique(train_df['series_id']):\n",
    "    temp = train_df[train_df['series_id']==col].set_index('date')\n",
    "    SP500 = train_df[train_df['series_id']=='SP500'].set_index('date')\n",
    "    idx = pd.date_range(min(np.unique(SP500.index)), max(np.unique(SP500.index)))\n",
    "    temp.index = pd.DatetimeIndex(temp.index)\n",
    "    temp = temp.reindex(idx, fill_value=None)\n",
    "    temp['series_id']=col\n",
    "    temp['value'] = temp['value'].interpolate(method='time')\n",
    "    df_train = df_train.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame()\n",
    "for col in np.unique(test_df['series_id']):\n",
    "    temp = test_df[test_df['series_id']==col].set_index('date')\n",
    "    idx = pd.date_range(min(np.unique(temp.index)), max(np.unique(temp.index)))\n",
    "    temp.index = pd.DatetimeIndex(temp.index)\n",
    "    temp = temp.reindex(idx, fill_value=None)\n",
    "    temp['series_id']=col\n",
    "    temp['value'] = temp['value'].interpolate(method='time')\n",
    "    df_test = df_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "total = np.unique(df_train['series_id'])\n",
    "res = np.unique(df_train[df_train['value'].isnull()]['series_id'])\n",
    "use_feat = list((Counter(total)-Counter(res)-Counter(['SP500'])).elements())\n",
    "len(use_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[df_train['series_id'].isin(use_feat)]\n",
    "X_train = X_train.pivot(columns='series_id')\n",
    "\n",
    "X_train.columns = X_train.columns.droplevel(0)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "Y_train = df_train[df_train['series_id']=='SP500']\n",
    "Y_train = Y_train.pivot(columns='series_id')\n",
    "Y_train.columns = Y_train.columns.droplevel(0)\n",
    "Y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.926384</th>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999611</th>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model\n",
       "Score                  \n",
       "0.926384            KNN\n",
       "0.999611  Random Forest\n",
       "1.000000  Decision Tree"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "score_random_forest = random_forest.score(X_train, Y_train)\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = 3) \n",
    "knn.fit(X_train, Y_train)  \n",
    "score_knn = knn.score(X_train, Y_train)\n",
    "\n",
    "decision_tree = DecisionTreeRegressor() \n",
    "decision_tree.fit(X_train, Y_train)   \n",
    "score_decision_tree = decision_tree.score(X_train, Y_train)\n",
    "\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['KNN', \n",
    "              'Random Forest', \n",
    "              'Decision Tree'],\n",
    "    'Score': [score_knn, score_random_forest, score_decision_tree]})\n",
    "result_df = results.sort_values(by='Score')\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AAA10Y': 0.0030577252503654483,\n",
       " 'BAA10Y': 0.1256156084257581,\n",
       " 'DEXCHUS': 0.15618398381570842,\n",
       " 'DEXUSEU': 0.6399125609450178,\n",
       " 'DEXUSUK': 0.00879271261192378,\n",
       " 'DFII10': 0.0005883158675934175,\n",
       " 'DFII20': 0.006474792590573117,\n",
       " 'DFII30': 0.0010893148657149141,\n",
       " 'DFII5': 0.0030123320743439905,\n",
       " 'DFII7': 0.0003996415335726453,\n",
       " 'DLTIIT': 0.0005271265293476373,\n",
       " 'DPCREDIT': 7.309690628454024e-06,\n",
       " 'DPRIME': 0.0008383943903802302,\n",
       " 'EFFR': 0.04291902373141397,\n",
       " 'INFECTDISEMVTRACKD': 5.8222801108734016e-05,\n",
       " 'IOER': 0.0009232835202386064,\n",
       " 'IORR': 0.0008371329604329438,\n",
       " 'T10YIE': 0.006905113772597543,\n",
       " 'TEDRATE': 0.0012896157568257462,\n",
       " 'WLEMUINDXD': 0.0005677888664544732}"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RandomForestRegressor(n_estimators=100)\n",
    "reg.fit(X_train, Y_train)\n",
    "dict(zip(X_train.columns, reg.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = df_train[df_train['series_id'].isin(['BAA10Y','DEXCHUS','DEXUSEU'])].pivot(columns='series_id')\n",
    "f.columns = f.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[df_train['series_id'].isin(['BAA10Y','DEXCHUS','DEXUSEU'])]\n",
    "X_train = X_train.pivot(columns='series_id')\n",
    "X_train.columns = X_train.columns.droplevel(0)\n",
    "#X_train.reset_index(drop=True, inplace=True)\n",
    "Y_train = df_train[df_train['series_id']=='SP500']\n",
    "Y_train = Y_train.pivot(columns='series_id')\n",
    "Y_train.columns = Y_train.columns.droplevel(0)\n",
    "#Y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bestfeat = X_train[['BAA10Y','DEXCHUS','DEXUSEU']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1390.7636    , 1355.903     , 1358.0523    , ..., 2679.8407    ,\n",
       "       2683.10196667, 2676.10236667])"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train, x_test, y_train, y_test = X_train[-7:][0:6], X_train[-7:][6:7], Y_train[-7:][0:6], Y_train[-7:][6:7]\n",
    "#random_forest = RandomForestRegressor(n_estimators=100)\n",
    "#random_forest.fit(x_train, y_train)\n",
    "#random_forest.score(x_train, y_train)\n",
    "rf =  RandomForestRegressor()\n",
    "params = [{'n_estimators':[100],'max_features':[1,2,3],}]\n",
    "tscv = TimeSeriesSplit(n_splits=100)\n",
    "clf = GridSearchCV(rf, params, cv=tscv, scoring=['r2'], refit=False, verbose=0)\n",
    "rf_model = clf.fit(X_train_bestfeat,Y_train.values.ravel())\n",
    "pr2 = rf_model.cv_results_['params'][ np.argmin(rf_model.cv_results_['rank_test_r2'])]\n",
    "rf.set_params(**pr2)\n",
    "rf.fit(X_train_bestfeat,Y_train.values.ravel())\n",
    "\n",
    "rf.predict(X_train_bestfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995210448802597"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train_bestfeat,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "for series, df_series in df_train.groupby('series_id'):\n",
    "    name_df = series\n",
    "    exec(name_df + \"= df_series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-12-29 00:00:00')"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace min(SP500.index) with given date\n",
    "d = (max(SP500.index)-min(SP500.index)).days\n",
    "max(SP500.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:171: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:191: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n",
      "  start=index[0], end=index[-1], freq=freq)\n",
      "/anaconda3/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:171: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             ARIMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                D.value   No. Observations:                 2510\n",
      "Model:                 ARIMA(2, 1, 2)   Log Likelihood               -9665.223\n",
      "Method:                       css-mle   S.D. of innovations             11.379\n",
      "Date:                Sun, 11 Apr 2021   AIC                          19342.446\n",
      "Time:                        02:13:42   BIC                          19377.414\n",
      "Sample:                    02-15-2011   HQIC                         19355.138\n",
      "                         - 12-29-2017                                         \n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             0.5339      0.240      2.227      0.026       0.064       1.004\n",
      "ar.L1.D.value     1.1007      0.134      8.225      0.000       0.838       1.363\n",
      "ar.L2.D.value    -0.8030      0.080    -10.004      0.000      -0.960      -0.646\n",
      "ma.L1.D.value    -1.0738      0.125     -8.584      0.000      -1.319      -0.829\n",
      "ma.L2.D.value     0.8151      0.076     10.760      0.000       0.667       0.964\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                  Real          Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1            0.6853           -0.8807j            1.1159           -0.1448\n",
      "AR.2            0.6853           +0.8807j            1.1159            0.1448\n",
      "MA.1            0.6587           -0.8905j            1.1076           -0.1486\n",
      "MA.2            0.6587           +0.8905j            1.1076            0.1486\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2679.47943921, 2679.69757412, 2679.86050987, 2680.0521874 ,\n",
       "       2680.3198251 , 2680.64799027, 2680.9817802 ])"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "model = ARIMA(SP500.value[~np.isnan(SP500.value)], order=(2, 1 ,2))  \n",
    "fitted = model.fit(disp=-1)  \n",
    "print(fitted.summary())\n",
    "\n",
    "# Forecast\n",
    "fc, se, conf = fitted.forecast(7, alpha=0.05)  # 95% conf\n",
    "\n",
    "(fc + random_forest.predict(x_test)[0])/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
